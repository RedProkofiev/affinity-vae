{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314eccba",
   "metadata": {},
   "source": [
    "# Post processing notebook \n",
    "\n",
    "### This notebook import the visualisation functions from the main library and loads the state and meta file and allows you to modify the appearance of the output of Affinity-VAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be55a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, fixed, Dropdown\n",
    "from avae.vis import latent_embed_plot_umap, latent_embed_plot_tsne\n",
    "from avae.utils import colour_per_class\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf4e2d",
   "metadata": {},
   "source": [
    "### The following functions take in the path of the meta and the state file respectively and load them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db474560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(meta_fn, device=\"cpu\"):\n",
    "    meta_df = pd.read_pickle(meta_fn)\n",
    "\n",
    "    mu = meta_df[\n",
    "        [col for col in meta_df.columns if col.startswith(\"lat\")]\n",
    "    ].to_numpy()  # Assuming the column name for latent variables is 'latent'\n",
    "    \n",
    "    labels = meta_df[\"id\"]\n",
    "\n",
    "    pose = meta_df[\n",
    "        [col for col in meta_df.columns if col.startswith(\"pos\")]\n",
    "    ].to_numpy()\n",
    "    \n",
    "    std = meta_df[\n",
    "        [col for col in meta_df.columns if col.startswith(\"std\")]\n",
    "    ].to_numpy()\n",
    "    \n",
    "    #### why is there an 0.5 attached to beginning of each std array so that the size is 17?\n",
    "    std = std[:,1:]\n",
    "    \n",
    "    z =  np.random.randn(*std.shape)  * std + mu\n",
    "    \n",
    "    return mu, pose, labels, std, z\n",
    "    \n",
    "\n",
    "def load_model(model_fn, device=\"cpu\"):\n",
    "    checkpoint = torch.load(model_fn)\n",
    "    model = checkpoint[\"model_class_object\"]\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed324a89",
   "metadata": {},
   "source": [
    "# Enter the path for the saved model and corresponding meta file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c5c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = '/Users/mfamili/work/exp_avae/alphanum/states/avae_13_38_11_01_2024_E989_16_1.pt'\n",
    "meta_fn = '/Users/mfamili/work/exp_avae/alphanum/states/meta_13_38_11_01_2024_E989_16_1.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbcb862",
   "metadata": {},
   "source": [
    "# Grab the Information in the meta file and load the model\n",
    "### From the meta file \n",
    "1. `mu`: mean of the latents ($\\mu$)\n",
    "2. `std`: standard deviation of the latents ($\\sigma$)\n",
    "3. `p`: $pose$\n",
    "4. `labels`: class labels\n",
    "5. `z`: sampled latent ($z$) \n",
    "### model loaded to `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26168d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, p, labels, std, z = load_meta(meta_fn)\n",
    "model =load_model(model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122cebd8",
   "metadata": {},
   "source": [
    "# Configure latent embedding:\n",
    "#### select the following to plot the UMAP embedding of the latent space : \n",
    "1. `select_function`: The drop down list allows you to choose between UMAP and TSNE for your dimentionality reduction of the latent embeddings. \n",
    "2. `rs` : This slider sets the random state for the UMAP plot.\n",
    "3. `perplexity`: This slider sets the perplexity for the TSNE plot.\n",
    "4. `Data Type`: This drop down list allows you to select which variable to plot (`z` : stochastic sample of latent space, `mu`: the mean of the latent space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472410a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1308995192d84fa495ff56e3ddc132f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Function', options=('latent_embed_plot_umap', 'latent_embed…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(function, data_type, rs, perplexity)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the slider widget\n",
    "random_state_slider = IntSlider(min=0, max=100, step=1, value=42)\n",
    "perplexity_slider = IntSlider(min=2, max=100, step=1, value=40, description='Perplexity')\n",
    "\n",
    "# Define the dropdown widget for selecting the function\n",
    "function_selector = Dropdown(options=['latent_embed_plot_umap', 'latent_embed_plot_tsne'],\n",
    "                             value='latent_embed_plot_umap', description='Select Function')\n",
    "\n",
    "# Use the interact function with both widgets\n",
    "interact(lambda function, data_type, rs, perplexity: (latent_embed_plot_umap(xs=z if data_type == 'z' and function == 'latent_embed_plot_umap' else mu,\n",
    "                                                                  ys=labels, rs=rs, display=True)\n",
    "                                          if function == 'latent_embed_plot_umap'\n",
    "                                          else latent_embed_plot_tsne(xs=z if data_type == 'z' and function == 'latent_embed_plot_tsne' else mu,\n",
    "                                                                      ys=labels, perplexity=perplexity, display=True)),\n",
    "         function=function_selector,\n",
    "         data_type=Dropdown(options=['z', 'mu'], value='z', description='Data Type'),\n",
    "         rs=random_state_slider,\n",
    "         perplexity = perplexity_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd46bd9",
   "metadata": {},
   "source": [
    "## Creating new latent interpolation plots\n",
    "\n",
    "1. choose the size of your input images : `dsize`\n",
    "\n",
    "2. choose the plot interpolation steps via the slider : `num_int`\n",
    "\n",
    "note that everytime you drag the `num_int` slider the plot corners change, if you would like to start from a given number of interpolation steps change the value of `init_interpolation_steps` in the code cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c387be43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c0f241b924415689e1c18a60a4f120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='num_int', max=20, min=2), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(num_int)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from avae.vis import latent_4enc_interpolate_plot\n",
    "\n",
    "dsize = [64,64]\n",
    "init_interpolation_steps = 10\n",
    "\n",
    "number_interpolation = IntSlider(min=2, max=20, step=1, value=init_interpolation_steps)\n",
    "interact(lambda num_int: latent_4enc_interpolate_plot(dsize= dsize, xs= torch.from_numpy(z).to(dtype=torch.float), \n",
    "                             ys= labels, vae = model ,device = \"cpu\", plots_config = f\"1,{num_int}\", \n",
    "                             poses = p, display = True),num_int=number_interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1fbf5",
   "metadata": {},
   "source": [
    "## Creating new pose interpolation plots\n",
    "1. choose the size of your input images : `dsize`\n",
    "2. choose the plot interpolation steps via the slider : `number_of_samples`\n",
    "3. choose the classes you would like the interpolation to be generated for via the variable : `pose_vis_class`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea8b905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65848c9a75d24b68a6b06b58e69187b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='number_of_samples', max=20, min=2), Output()), _dom_cla…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(number_of_samples)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from avae.vis import pose_class_disentanglement_plot\n",
    "\n",
    "dsize= [64,64]\n",
    "pose_vis_class = \"i,e\"\n",
    "\n",
    "num_int = IntSlider(min=2, max=20, step=1, value=10)\n",
    "interact(lambda number_of_samples:pose_class_disentanglement_plot(dsize= [64,64], x= torch.from_numpy(z).to(dtype=torch.float), \n",
    "                                y= labels, pose_vis_class=pose_vis_class, poses = p, vae = model,\n",
    "                                device = \"cpu\", number_of_samples = number_of_samples ,display = True), number_of_samples = num_int )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e93b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8dec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ee446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_tomlavae_env",
   "language": "python",
   "name": "new_tomlavae_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
